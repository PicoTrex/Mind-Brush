import os
import sys
import json
import logging
import asyncio
import shutil
import base64
import mimetypes
import re  # [New]
from tqdm import tqdm
from pathlib import Path
from datetime import datetime
from typing import List, Optional
from contextlib import AsyncExitStack
from mcp.client.stdio import stdio_client
from logging.handlers import RotatingFileHandler
from mcp import ClientSession, StdioServerParameters
from geopy.geocoders import Nominatim # [New]
from geopy.exc import GeocoderTimedOut, GeocoderServiceError # [New]

from model import Model  # è‡ªå®šä¹‰æ¨¡å‹å°è£…ç±»

# ================= é…ç½®åŒºåŸŸ =================
# ä»£ç†é…ç½®
os.environ["http_proxy"] = "http://127.0.0.1:7897"
os.environ["https_proxy"] = "http://127.0.0.1:7897"

# è·¯å¾„é…ç½®
IMAGE_BASE_ROOT = Path(r"E:\Idea2Image-Bench\Benchmark\Idea2Image-Bench") # å›¾åƒæ•°æ®çš„æ ¹ç›®å½•
INPUT_JSONL_PATH = r"E:\Idea2Image-Bench\Benchmark\Idea2Image-Bench\checklist\2_Weather.jsonl" # è¾“å…¥æ–‡ä»¶è·¯å¾„
OUTPUT_ROOT_PATH = Path(r"E:\Idea2Image-Bench\Idea2Image-Agent\agent-6\output") # ç»“æœè¾“å‡ºæ ¹ç›®å½•

# è®¾ç½®å·¥ä½œç›®å½•ä¸ºå½“å‰è„šæœ¬æ‰€åœ¨è·¯å¾„
os.chdir(os.path.dirname(os.path.abspath(__file__)))

# å…¨å±€å˜é‡
temp_dir_path = None
logger = None

# ================= æ—¥å¿—ä¸å·¥å…·å‡½æ•° =================

class JsonFormatter(logging.Formatter):
    def format(self, record):
        convs_out = []
        if isinstance(record.args, tuple) and len(record.args) > 0 and isinstance(record.args[0], list):
             for conv in record.args[0]:
                try:
                    if 'tool_calls' in conv:
                        for tool_call in conv['tool_calls']:
                            if isinstance(tool_call['function']['arguments'], str):
                                tool_call['function']['arguments'] = json.loads(tool_call['function']['arguments'])
                except:
                    pass
                finally:
                    convs_out.append(conv)
        
        log_record = {
            "timestamp": self.formatTime(record, self.datefmt),
            "level": record.levelname,
            "conversations": convs_out
        }
        return json.dumps(log_record, ensure_ascii=False, indent=4)

def init_globel_params():
    global temp_dir_path, logger
    # å®šä¹‰å›ºå®šçš„ä¸­è½¬ç«™ï¼Œä½äºå½“å‰ç›®å½•ä¸‹çš„ tmp/buffer
    temp_dir_path = Path('./tmp/buffer1').absolute()
    
    # æ¯æ¬¡å¯åŠ¨å‰æ¸…ç†æ•´ä¸ªä¸­è½¬ç«™ï¼Œä¿è¯ç¯å¢ƒå¹²å‡€
    if temp_dir_path.exists():
        try:
            shutil.rmtree(temp_dir_path)
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†ç¼“å­˜ç›®å½•å¤±è´¥ (å¯èƒ½æ˜¯æ–‡ä»¶å ç”¨): {e}")

    temp_dir_path.mkdir(parents=True, exist_ok=True)

    # é¢„å…ˆåˆ›å»ºå­ç›®å½•ï¼Œä¾›å·¥å…·ä½¿ç”¨
    (temp_dir_path / 'draw_output').mkdir(parents=True, exist_ok=True)
    (temp_dir_path / 'search').mkdir(parents=True, exist_ok=True)
    (temp_dir_path / 'search_text').mkdir(parents=True, exist_ok=True)

    logger = logging.getLogger("text_logger")
    logger.setLevel(logging.INFO)
    # ä½¿ç”¨ RotatingFileHandler é˜²æ­¢å•ä¸ªæ—¥å¿—è¿‡å¤§
    handler = RotatingFileHandler(temp_dir_path / "app.log", maxBytes=10*1024*1024, backupCount=5, encoding='utf-8')
    handler.setFormatter(JsonFormatter())
    logger.addHandler(handler)
    return temp_dir_path, logger

def clear_buffer_files(dir_path: Path):
    """åªæ¸…ç©ºæ–‡ä»¶ï¼Œä¸åˆ æ–‡ä»¶å¤¹"""
    if not dir_path.exists(): return
    for item in dir_path.iterdir():
        if item.name == "app.log": continue # ä¿ç•™æ—¥å¿—æ–‡ä»¶å¥æŸ„
        try:
            if item.is_file(): item.unlink()
            elif item.is_dir(): shutil.rmtree(item)
        except: pass

def encode_file(file_path):
    mime_type, _ = mimetypes.guess_type(file_path)
    if not mime_type or not mime_type.startswith("image/"):
        return None # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œåªæ˜¯è¿”å›Noneè¡¨ç¤ºæ— æ³•ç¼–ç 

    try:
        with open(file_path, "rb") as image_file:
            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
        return f"data:{mime_type};base64,{encoded_string}"
    except IOError:
        return None

# ================= MCP å®¢æˆ·ç«¯ç±» =================

class MCPClient:
    def __init__(self, model_name: str, provider: str, base_url: str = None, api_key: str = None, 
                 global_env: dict = {}, servers_info: dict = {}, temp_dir_path: Path = None, 
                 need_context: bool = True, system_prompt: str = None):
        
        self.model_name = model_name
        self.servers_info = servers_info
        self.global_env = global_env
        self.sessions = {}
        self.tool_mapping = {}
        self.exit_stack = AsyncExitStack()
        self.client = Model(
            model_name=model_name,
            provider=provider,
            base_url=base_url,
            api_key=api_key,
            system_prompt=system_prompt
        )
        self.temp_dir_path = temp_dir_path
        self.need_context = need_context
        self.context = []

    async def initialize_sessions(self):
        for server_name, server_info in self.servers_info.items():
            # å¼ºåˆ¶å°†å·¥å…·çš„è¾“å‡ºæŒ‡å‘æˆ‘ä»¬çš„å›ºå®šä¸­è½¬ç«™
            if server_name == 'ImageGen':
                server_info['args'][-1] = str(self.temp_dir_path / 'draw_output')
            if 'RAG' in server_name or 'Image_RAG' in server_name:
                server_info['args'][-1] = str(self.temp_dir_path / 'search')
            if 'Text_RAG' in server_name:
                 server_info['args'][-1] = str(self.temp_dir_path / 'search_text')
                
            # åˆå¹¶ç¯å¢ƒå˜é‡
            current_env = os.environ.copy()
            current_env.update(self.global_env)
            if server_info.get('env'):
                current_env.update(server_info['env'])

            server_params = StdioServerParameters(
                command=server_info['command'],
                args=server_info['args'],
                env=current_env,
            )

            write, read = await self.exit_stack.enter_async_context(stdio_client(server_params))
            session = await self.exit_stack.enter_async_context(ClientSession(write, read))
            await session.initialize()

            self.sessions[server_name] = session
            self.tool_mapping[server_name] = session # ç®€åŒ–æ˜ å°„é€»è¾‘ï¼Œæˆ–è€…ä¿æŒåŸæœ‰çš„éå† logic

            # è·å–æ”¯æŒçš„å·¥å…·å¹¶å»ºç«‹æ˜ å°„ (å…¼å®¹åŸæœ‰é€»è¾‘)
            response = await session.list_tools()
            for tool in response.tools:
                prefixed_name = f"{server_name}_{tool.name}"
                self.tool_mapping[prefixed_name] = (session, tool.name)
            
            # print(f"å·²è¿æ¥: {server_name}")

    async def cleanup(self):
        await self.exit_stack.aclose()

    # [New] æ·»åŠ åœ°ç†ç¼–ç é¢„å¤„ç†å‡½æ•°
    def _preprocess_coordinates(self, text: str) -> str:
        """
        è¯†åˆ«æ–‡æœ¬ä¸­çš„åœ°ç†åæ ‡å¹¶æ›¿æ¢ä¸ºåœ°åï¼ˆç²¾ç¡®åˆ°åŸå¸‚/åŒºå¿ï¼‰ã€‚
        æ”¯æŒæ ¼å¼ç¤ºä¾‹ï¼š
        - 39.9917N, 116.3906E
        - 39Â°59'30.1"N 116Â°23'26.2"E
        - 39.9917, 116.3906
        """
        geolocator = Nominatim(user_agent="mcp_geo_bot", timeout=10)

        pattern = re.compile(
            r'(?:'
            # æ¨¡å¼1: çº¬åº¦(å«N/S) + åˆ†éš”ç¬¦ + ç»åº¦(å«E/W)
            r'(?:[-+]?\d{1,3}(?:\.\d+)?(?:[Â°d]\s*\d{1,2}(?:\.\d+)?)?(?:[\'â€²]\s*\d{1,2}(?:\.\d+)?)?[â€³"]?\s*[NS])'
            r'\s*[,ï¼Œ\s]\s*'
            r'(?:[-+]?\d{1,3}(?:\.\d+)?(?:[Â°d]\s*\d{1,2}(?:\.\d+)?)?(?:[\'â€²]\s*\d{1,2}(?:\.\d+)?)?[â€³"]?\s*[EW])'
            r')|(?='
            # æ¨¡å¼2: çº¯æ•°å­—å¯¹
            r'[-+]?\d+\.\d+\s*[,ï¼Œ]\s*[-+]?\d+\.\d+'
            r')'
            r'(?:[-+]?\d+\.\d+\s*[,ï¼Œ]\s*[-+]?\d+\.\d+)',
            re.IGNORECASE | re.VERBOSE
        )

        def replacer(match):
            coord_str = match.group(0)
            try:
                location = geolocator.reverse(coord_str, language='en')
                
                if location and location.raw.get('address'):
                    addr = location.raw['address']
                    
                    state = addr.get('state')
                    country = addr.get('country')
                    
                    parts = [p for p in [state, country] if p]
                    
                    seen = set()
                    cleaned_parts = []
                    for p in parts:
                        if p not in seen:
                            cleaned_parts.append(p)
                            seen.add(p)
                            
                    place_name = ", ".join(cleaned_parts)
                    
                    # print(f"ğŸŒ [Geo Detect] åæ ‡ '{coord_str}' å·²æ›¿æ¢ä¸º -> '{place_name}'")
                    return f"{place_name}"
            
            except (GeocoderTimedOut, GeocoderServiceError) as e:
                print(f"âš ï¸ [Geo Warning] API è¯·æ±‚è¶…æ—¶: {e}")
            except Exception as e:
                print(f"âš ï¸ [Geo Error] è§£æå‡ºé”™: {e}")
            
            return coord_str

        return pattern.sub(replacer, text)

    async def process_query(self, query: str, image_path: Optional[str] = None):
        """
        å¤„ç†å•æ¡ç”¨æˆ·æŸ¥è¯¢ï¼Œæ”¯æŒå›¾åƒè·¯å¾„æ³¨å…¥
        """
        # 1. æ¯æ¬¡å¤„ç†å‰æ¸…ç©ºä¸Šä¸‹æ–‡ (æ‰¹é‡æ¨¡å¼ä¸‹æ¯ä¸ªä»»åŠ¡æ˜¯ç‹¬ç«‹çš„)
        self.context = [] 
        
        # [New] åœ¨å¤„ç†å‰å…ˆè¿›è¡Œåœ°ç†åæ ‡è§£æ (ä½¿ç”¨ asyncio.to_thread é¿å…é˜»å¡)
        # print("ğŸ” æ­£åœ¨æ£€æŸ¥åœ°ç†ä½ç½®ä¿¡æ¯...")
        processed_query = await asyncio.to_thread(self._preprocess_coordinates, query)
        user_content = processed_query
        
        if image_path and ", " in image_path:
            # å…¼å®¹å¤šå¼ å›¾ç‰‡è·¯å¾„ï¼Œåªé€‰å–ç¬¬ä¸€å¼ å›¾åƒ
            image_path = image_path.split(", ")[0]
        
        # 2. å¤„ç†å›¾ç‰‡è·¯å¾„æ³¨å…¥
        if image_path:
            clean_path = str(image_path).strip().strip('"').strip("'")
            if os.path.exists(clean_path):
                # æ³¨å…¥ System Noteï¼ŒæŒ‡å¯¼ Agent ä½¿ç”¨ intent_analyzer è¯»å–å›¾ç‰‡
                user_content += f"\n\n[System Note: The user has provided an input image located at: {clean_path}. If you call 'intent_analyzer', you MUST pass this path string to its 'image_path' argument.]"
            else:
                print(f"âš ï¸ å›¾ç‰‡è·¯å¾„ä¸å­˜åœ¨: {clean_path}")

        messages = self.context
        messages.append({"role": "user", "content": user_content})

        # 3. æ”¶é›†å·¥å…·å®šä¹‰
        available_tools = []
        for server_id, session in self.sessions.items():
            try:
                response = await session.list_tools()
                for tool in response.tools:
                    prefixed_name = f"{server_id}_{tool.name}"
                    available_tools.append({
                        "type": "function",
                        "function": {
                            "name": prefixed_name,
                            "description": tool.description,
                            "parameters": tool.inputSchema,
                        },
                    })
            except: pass 

        # 4. è°ƒç”¨ LLM
        try:
            response = await self.client.chat(messages=messages, tools=available_tools)
        except Exception as e:
            print(f"âŒ LLM è°ƒç”¨å¤±è´¥: {e}")
            return

        message = response[0]
        if message.content:
            messages.append({"role": "assistant", "content": message.content})

        # 5. å¾ªç¯å·¥å…·è°ƒç”¨
        loop_count = 0
        MAX_LOOPS = 15 # é˜²æ­¢æ­»å¾ªç¯

        while message.tool_calls and loop_count < MAX_LOOPS:
            loop_count += 1
            for tool_call in message.tool_calls:
                prefixed_name = tool_call.function.name
                
                content_str = "Error: Tool not found"
                if prefixed_name in self.tool_mapping:
                    session, original_tool_name = self.tool_mapping[prefixed_name]
                    try:
                        tool_args = json.loads(tool_call.function.arguments)
                        # print(f"ğŸ› ï¸ Tool: {prefixed_name}")
                        result = await session.call_tool(original_tool_name, tool_args)
                        
                        # å…¼å®¹ä¸åŒç±»å‹çš„ Content è¿”å›
                        if hasattr(result, 'content') and isinstance(result.content, list):
                            content_str = "".join([item.text for item in result.content if hasattr(item, 'text')])
                        else:
                            content_str = str(result)
                            
                    except Exception as e:
                        content_str = f"Error executing tool: {str(e)}"
                        print(f"âŒ Tool Error ({prefixed_name}): {e}")

                # è®°å½•å·¥å…·ç»“æœåˆ°å†å²
                messages.extend([
                    {
                        "role": "assistant", 
                        "tool_calls": [{
                            "id": tool_call.id, 
                            "type": "function", 
                            "function": {"name": prefixed_name, "arguments": tool_call.function.arguments}
                        }]
                    },
                    {"role": "tool", "tool_call_id": tool_call.id, "content": content_str}
                ])
                
                # è®°å½•ä¸­é—´æ—¥å¿—
                if logger:
                    logger.info("Intermediate Result", [{
                        "role": "system_notification",
                        "tool_name": prefixed_name,
                        "content": content_str
                    }])

            # å†æ¬¡è°ƒç”¨ LLM
            try:
                response = await self.client.chat(messages=messages, tools=available_tools)
                message = response[0]
                if message.content:
                    messages.append({"role": "assistant", "content": message.content})
            except Exception as e:
                print(f"âŒ LLM é€’å½’è°ƒç”¨å¤±è´¥: {e}")
                break
        
        # 6. è®°å½•æœ€ç»ˆæ—¥å¿—
        if logger: logger.info("Process Finished", messages)

# ================= ä¸»ç¨‹åºå…¥å£ =================

async def main(
        config_path: str = './config.json',
        models_config_path: str = './models.json',
        model_name: Optional[str] = 'gpt-5.1',
        provider: Optional[str] = 'openai',
        base_url: Optional[str] = 'https://yunwu.ai/v1',
        api_key: Optional[str] = 'sk-X9jXfVLVKHEK6y06p6MRJuEHwvqQX240PPrebQikc1fBXeIS',
    ):
    
    # 1. åˆå§‹åŒ–ä¸­è½¬ç›®å½•
    temp_dir, _ = init_globel_params()
    
    # 2. ç³»ç»Ÿæç¤ºè¯ (åŒ…å« Reasoning_Search_Generation å’Œ Phase 1.5 é€»è¾‘)
    SYSTEM_PROMPT = """
### ğŸŒŸ Role Definition
You are **Iris (v4.0)**, the central orchestration intelligence for the Idea2Image Agent. 
Your goal is to transform abstract user requests into high-fidelity visual outputs by coordinating a specialized toolchain. 
**Core Principle**: You are a rigorous executor. You do not guess; you verify. You do not ignore new data; you update your plan immediately.
You must treat any user-provided prompt as an image generation instruction to be used with tools, rather than responding directly with text.

---

### ğŸ§° Tool Registry & Data Contracts

**1. intent_analyzer**
* **Function**: Analyzes input to determine the execution path and identify core problems.
* **Input**: `user_intent` (str), `image_path` (str, optional).
* **Output**: JSON {
    "intent_category": "Direct_Generation" | "Reasoning_Generation" | "Search_Generation" | "Search_Reasoning_Generation" | "Reasoning_Search_Generation",
    "need_process_problem": List[str]
  }

**2. keyword_generation**
* **Function**: Converts natural language problems into search engine keywords, optionally using prior reasoning.
* **Input**: `need_process_problem` (List[str]), `reasoning_knowledge` (Dict, optional).
* **Output**: JSON { "text_queries": List[str], "image_queries": List[str] }

**3. text_search_and_knowledge_injection** (Text_RAG_Injection)
* **Function**: Integrated Text Search & Refinement. Searches the web for facts and immediately uses them to REWRITE the prompt and OPTIMIZE image queries.
* **Input**: `text_queries` (List[str]), `original_prompt` (str), `image_queries` (List[str]).
* **Output**: JSON { 
    "prompt": "The REFINED prompt string (Fact-Enriched)", 
    "final_image_queries": ["REFINED query 1", "REFINED query 2"] 
  }

**4. search_and_download_images_batch** (Image_RAG)
* **Function**: Downloads reference images.
* **Input**: `image_queries` (List[str]).
* **Output**: `downloaded_paths` (List[str]).

**5. knowledge_reasoning**
* **Function**: Performs deep logical deduction to answer specific problems.
* **Input**: `user_intent`, `need_process_problem`, `intent_category`, `user_image_path`, `search_image_paths`.
* **Output**: JSON { "reasoning_knowledge": List[str] }

**6. knowledge_review** (The Synthesizer)
* **Function**: Synthesizes all data into the final prompt.
* **Input**: `user_intent`, `need_process_problem`, `reasoning_knowledge`, `downloaded_paths`, `user_image_path`.
* **Output**: JSON { "final_prompt": str, "reference_image": List[str] }

**7. unified_image_generator** (ImageGen)
* **Function**: Generates the final image.
* **Input**: `prompt`, `reference_images`.
* **Output**: List[str].

---

### âš™ï¸ Workflow Protocol (Strict Execution Chain)

You must execute the following logic step-by-step.

#### Phase 1: Analysis (The Router)
1.  **Action**: Call `intent_analyzer(user_intent, image_path)`.
2.  **Observation**: Identify `intent_category` and `need_process_problem`.
3.  **Branching**:
    * IF `Direct_Generation`: Go to **Phase 5**.
    * IF `Reasoning_Generation`: Go to **Phase 4**.
    * IF `Reasoning_Search_Generation`: Go to **Phase 2**.
    * IF `Search_Generation` OR `Search_Reasoning_Generation`: Go to **Phase 3**.

#### Phase 2: Pre-Search Reasoning (Only for Reasoning_Search_Generation)
1.  **Action**: Call `knowledge_reasoning`.
    * **Inputs**: `user_intent`, `need_process_problem`, `intent_category`, `user_image_path` (Search inputs are None).
    * **Get**: `reasoning_knowledge`.
3.  **Transition**: Go to **Phase 3**.

#### Phase 3: Retrieval (The RAG Loop)
1.  **Action**: Call `keyword_generation`.
    * **Inputs**: 
        * `need_process_problem`: (From Phase 1)
        * `reasoning_knowledge`: you MUST input it explicitly from Phase 2 (if available).
    * **Get**: `text_queries`, `image_queries` (Draft Version).

2.  **Logic Check & Search Execution**:
    * **CASE A: Text Search IS Required (`text_queries` is NOT empty)**
        * **Action**: Call `text_search_and_knowledge_injection(text_queries, user_intent, image_queries)`.
        * **âš ï¸ DATA OVERRIDE PROTOCOL (CRITICAL)**: 
            * The tool returns a refined `prompt` and `final_image_queries`.
            * **YOU MUST DISCARD** the old `image_queries` and the old `user_intent`.
            * **YOU MUST USE** the new values for all subsequent steps.
            * *Reasoning Trace*: "I have received the fact-enriched prompt and optimized queries. I will use them as the new truth."
        * **Update Context**: 
            * Let `current_image_queries` = `final_image_queries` (from tool output).
            * Let `current_user_intent` = `prompt` (from tool output).
    * **CASE B: No Text Search (`text_queries` is empty)**
        * Let `current_image_queries` = `image_queries` (from Step 1).
        * Let `current_user_intent` = `user_intent` (Original input).

3.  **Action**: Call `search_and_download_images_batch(image_queries=current_image_queries)`.
    * **Get**: `downloaded_paths`.

4.  **Branching Return**:
    * IF `Search_Reasoning_Generation`: Go to **Phase 4**.
    * IF `Search_Generation` OR `Reasoning_Search_Generation`: Go to **Phase 5**. (For `Reasoning_Search`, reasoning was already done in Phase 1.5).

#### Phase 4: Reasoning (The Logic Engine)
1.  **Action**: Call `knowledge_reasoning`.
    * **Inputs**:
        * `user_intent`: **MUST use `current_user_intent`** (The refined prompt if Phase 3 updated it).
        * `search_image_paths`: Use `downloaded_paths` from Phase 3 (if available).
        * Pass other args as defined in registry.
    * **Get**: `reasoning_knowledge` (Update reasoning knowledge).
2.  **Transition**: Go to **Phase 5**.

#### Phase 5: Synthesis (The Review)
1.  **Action**: Call `knowledge_review`.
    * **Inputs**:
        * `original_request`: **MUST use `current_user_intent`** (The refined prompt if Phase 3 updated it).
        * `need_process_problem`: From Phase 1.
        * `reasoning_knowledge`: **CRITICAL CHECK**:
            * IF `Reasoning_Search_Generation`: Use `reasoning_knowledge` from **Phase 2**.
            * IF `Search_Reasoning_Generation` or `Reasoning_Generation`: Use `reasoning_knowledge` from **Phase 4**.
        * `downloaded_image_paths`: From Phase 3 (or empty List).
        * `user_image_path`: The user's uploaded image path.
    * **Get**: `final_prompt`, `reference_image`.

#### Phase 6: Execution (The Artist)
1.  **Action**: Call `unified_image_generator`.
    * **Inputs**:
        * `prompt`: `final_prompt` from Phase 5.
        * `reference_images`: `reference_image` from Phase 5.
    * **End**: Output the final result.

---

### ğŸš¨ Critical Rules

1.  **Context Update**: When `text_search_and_knowledge_injection` returns, you **MUST** map its output (`final_image_queries`, `prompt`) to `current_image_queries` and `current_user_intent`. **Do not blindly reuse the old variables.**
2.  **Variable Persistence**: If you generate `reasoning_knowledge` in Phase 2, you must carry it safely through Phase 3 and deliver it to Phase 5. Do not drop it.
3.  **No Hallucination**: If a tool returns an empty list `[]`, pass an empty list `[]`. Do not invent file paths.
4.  **Silent Operation**: Do not output your internal thought process to the user unless specifically asked. Just execute the tool calls.
"""
    # 3. è¯»å–é…ç½®
    with open(config_path, 'r') as f:
        config = json.load(f)
        
    global_env = {}
    if os.path.exists(models_config_path):
        with open(models_config_path, 'r') as f:
            models_data = json.load(f)
            global_env = models_data.get('global_env', {})
            if models_data.get('models'):
                m = models_data['models'][0]
                model_name = m.get('model', model_name)
                api_key = m.get('apiKey', api_key)
                base_url = m.get('apiBase', base_url)

    # 4. åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = MCPClient(
        model_name=model_name,
        provider=provider,
        base_url=base_url,
        api_key=api_key,
        servers_info=config['mcpServers'],
        temp_dir_path=temp_dir,
        need_context=False, # æ‰¹é‡æ¨¡å¼ä¸éœ€è¦ä¸Šä¸‹æ–‡
        system_prompt=SYSTEM_PROMPT,
        global_env=global_env
    )

    # 5. è¯»å– JSONL æ–‡ä»¶
    tasks = []
    if os.path.exists(INPUT_JSONL_PATH):
        with open(INPUT_JSONL_PATH, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    try:
                        tasks.append(json.loads(line))
                    except: pass
    else:
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {INPUT_JSONL_PATH}")
        return

    # è®¾ç½®è¾“å‡ºç›®å½•
    input_filename = os.path.basename(INPUT_JSONL_PATH).split('.')[0]
    final_output_root = OUTPUT_ROOT_PATH / input_filename
    final_output_root.mkdir(parents=True, exist_ok=True)

    try:
        print("æ­£åœ¨åˆå§‹åŒ–æœåŠ¡...")
        await client.initialize_sessions()
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {len(tasks)} ä¸ªä»»åŠ¡...")
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {final_output_root}")

        # å®šä¹‰ä¸­è½¬ç›®å½•å¿«æ·å¼•ç”¨
        buf_draw = temp_dir / 'draw_output'
        buf_img = temp_dir / 'search'
        buf_txt = temp_dir / 'search_text'

        # 6. æ‰¹é‡å¾ªç¯
        for item in tqdm(tasks, desc="Generating", unit="task"):
            try:
                # æå–ä»»åŠ¡ä¿¡æ¯
                prompt = item.get("Prompt")
                idx = item.get("ID", "unknown")
                type_name = item.get("Type", "unknown")
                rel_img_path = item.get("Image_Name")

                if not prompt: continue
                
                # --- æ‹¼æ¥ç»å¯¹å›¾ç‰‡è·¯å¾„ ---
                abs_img_path = None
                if rel_img_path:
                    abs_img_path = str(IMAGE_BASE_ROOT / rel_img_path)
                    if not os.path.exists(abs_img_path):
                        tqdm.write(f"âš ï¸ è­¦å‘Š: å›¾ç‰‡æ–‡ä»¶æœªæ‰¾åˆ°: {abs_img_path}")
                        # å³ä½¿æ‰¾ä¸åˆ°å›¾ç‰‡ï¼Œä¹Ÿç»§ç»­æ‰§è¡Œï¼Œåªæ˜¯ image_path ä¸º None

                # --- æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç»“æœ (è·³è¿‡é€»è¾‘) ---
                task_output_dir = final_output_root / f"{type_name}_{idx}"
                if (task_output_dir / "guided.png").exists() or (task_output_dir / "textgen.png").exists():
                    tqdm.write(f"â­ï¸  ID {idx} å·²å­˜åœ¨ç»“æœï¼Œè·³è¿‡ã€‚")
                    continue
                
                # A. æ¸…ç©ºä¸­è½¬ç«™ (åªåˆ æ–‡ä»¶ï¼Œä¸åˆ ç›®å½•)
                # å…ˆæ¸…ç©ºæ—¥å¿—æ–‡ä»¶å†…å®¹
                with open(temp_dir / "app.log", "w", encoding="utf-8") as f:
                    f.truncate(0)
                    
                clear_buffer_files(buf_draw)
                clear_buffer_files(buf_img)
                clear_buffer_files(buf_txt)

                # B. åˆ›å»ºä»»åŠ¡ç›®æ ‡æ–‡ä»¶å¤¹
                task_output_dir.mkdir(parents=True, exist_ok=True)

                # C. æ‰§è¡Œä»»åŠ¡ (ä¼ å…¥ prompt å’Œ ç»å¯¹è·¯å¾„çš„ image_path)
                await client.process_query(prompt, image_path=abs_img_path)

                # D. æ¬è¿ç»“æœ
                # 1. æ¬è¿ç”Ÿæˆçš„å›¾ç‰‡
                if buf_draw.exists():
                    for f in buf_draw.iterdir():
                        shutil.move(str(f), str(task_output_dir / f.name))
                
                # 2. æ¬è¿å›¾ç‰‡æœç´¢ç»“æœ
                if buf_img.exists() and any(buf_img.iterdir()):
                    (task_output_dir / "image_search").mkdir(exist_ok=True)
                    for f in buf_img.iterdir():
                        shutil.move(str(f), str(task_output_dir / "image_search" / f.name))

                # 3. æ¬è¿æ–‡æœ¬æœç´¢ç»“æœ
                if buf_txt.exists() and any(buf_txt.iterdir()):
                    (task_output_dir / "text_search").mkdir(exist_ok=True)
                    for f in buf_txt.iterdir():
                        shutil.move(str(f), str(task_output_dir / "text_search" / f.name))

                # 4. ä¿å­˜ metadata (åŒ…å«åŸå§‹ JSON ä¿¡æ¯)
                with open(task_output_dir / "metadata.json", "w", encoding="utf-8") as f:
                    json.dump(item, f, ensure_ascii=False, indent=2)
                    
                # 5. æ¬è¿æ—¥å¿— (åˆ·æ–° Handler é˜²æ­¢ä¸¢å¤±)
                if logger:
                    for h in logger.handlers: h.flush()
                shutil.copy(str(temp_dir / "app.log"), str(task_output_dir / "app.log"))

            except Exception as e:
                tqdm.write(f"âŒ ID {idx} å¤„ç†å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()

    finally:
        await client.cleanup()
        print(f"\nâœ… å…¨éƒ¨å®Œæˆã€‚")

if __name__ == "__main__":
    asyncio.run(main())